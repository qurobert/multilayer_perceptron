{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T10:37:41.976260Z",
     "start_time": "2025-01-21T10:37:41.953539Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('../data/processed/train_data.csv')\n",
    "\n",
    "train_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       1         2         3         4         5         6         7   \n",
       "0    0.0  0.096928  0.257694  0.103656  0.045387  0.487226  0.373965  \\\n",
       "1    1.0  0.667755  0.570172  0.683505  0.495228  0.554934  0.809214   \n",
       "2    0.0  0.103744  0.140345  0.106489  0.049799  0.221901  0.208975   \n",
       "3    0.0  0.173648  0.524518  0.167369  0.086320  0.396678  0.162444   \n",
       "4    0.0  0.150930  0.174839  0.143459  0.071432  0.548614  0.187811   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "450  0.0  0.090255  0.166723  0.103656  0.042630  0.408053  0.410159   \n",
       "451  0.0  0.220503  0.291512  0.216847  0.114104  0.555836  0.252500   \n",
       "452  0.0  0.345923  0.240446  0.321401  0.207466  0.105263  0.022606   \n",
       "453  1.0  0.331251  0.335137  0.327068  0.193425  0.481809  0.288080   \n",
       "454  0.0  0.246060  0.365573  0.231014  0.133701  0.248262  0.064413   \n",
       "\n",
       "            8         9        10  ...        22        23        24   \n",
       "0    0.733365  0.217445  0.530808  ...  0.084667  0.283316  0.075153  \\\n",
       "1    0.582709  0.743539  0.674242  ...  0.667022  0.571962  0.627970   \n",
       "2    0.140300  0.108350  0.646970  ...  0.073995  0.192164  0.075601   \n",
       "3    0.055740  0.080268  0.422727  ...  0.153682  0.617537  0.137308   \n",
       "4    0.025398  0.064115  0.850000  ...  0.109925  0.144723  0.096867   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "450  0.201640  0.142744  0.425253  ...  0.064141  0.097281  0.060511   \n",
       "451  0.165651  0.173211  0.374242  ...  0.185343  0.459488  0.174810   \n",
       "452  0.016987  0.031064  0.226263  ...  0.248310  0.230011  0.219284   \n",
       "453  0.263824  0.321223  0.307576  ...  0.324084  0.500533  0.316201   \n",
       "454  0.055834  0.087972  0.342929  ...  0.192458  0.554904  0.170178   \n",
       "\n",
       "           25        26        27        28        29        30        31  \n",
       "0    0.034285  0.508684  0.397018  1.000000  0.601375  0.524936  0.409681  \n",
       "1    0.467902  0.514627  0.709327  0.541534  0.997595  0.499310  0.481175  \n",
       "2    0.030697  0.179555  0.136324  0.111581  0.174811  0.338459  0.195855  \n",
       "3    0.066482  0.519910  0.109158  0.089856  0.210859  0.363493  0.173357  \n",
       "4    0.045075  0.371987  0.069244  0.017316  0.088625  0.392667  0.165027  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "450  0.024381  0.327082  0.209865  0.114537  0.164467  0.135817  0.349993  \n",
       "451  0.082703  0.644720  0.231598  0.229473  0.418557  0.244628  0.235668  \n",
       "452  0.122739  0.095754  0.022383  0.030879  0.114536  0.176030  0.040404  \n",
       "453  0.168133  0.595192  0.319692  0.325000  0.627835  0.318155  0.330972  \n",
       "454  0.089117  0.271611  0.059503  0.091454  0.255361  0.222551  0.090122  \n",
       "\n",
       "[455 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096928</td>\n",
       "      <td>0.257694</td>\n",
       "      <td>0.103656</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.487226</td>\n",
       "      <td>0.373965</td>\n",
       "      <td>0.733365</td>\n",
       "      <td>0.217445</td>\n",
       "      <td>0.530808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084667</td>\n",
       "      <td>0.283316</td>\n",
       "      <td>0.075153</td>\n",
       "      <td>0.034285</td>\n",
       "      <td>0.508684</td>\n",
       "      <td>0.397018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601375</td>\n",
       "      <td>0.524936</td>\n",
       "      <td>0.409681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667755</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.683505</td>\n",
       "      <td>0.495228</td>\n",
       "      <td>0.554934</td>\n",
       "      <td>0.809214</td>\n",
       "      <td>0.582709</td>\n",
       "      <td>0.743539</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667022</td>\n",
       "      <td>0.571962</td>\n",
       "      <td>0.627970</td>\n",
       "      <td>0.467902</td>\n",
       "      <td>0.514627</td>\n",
       "      <td>0.709327</td>\n",
       "      <td>0.541534</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.499310</td>\n",
       "      <td>0.481175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103744</td>\n",
       "      <td>0.140345</td>\n",
       "      <td>0.106489</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.221901</td>\n",
       "      <td>0.208975</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.108350</td>\n",
       "      <td>0.646970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.030697</td>\n",
       "      <td>0.179555</td>\n",
       "      <td>0.136324</td>\n",
       "      <td>0.111581</td>\n",
       "      <td>0.174811</td>\n",
       "      <td>0.338459</td>\n",
       "      <td>0.195855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173648</td>\n",
       "      <td>0.524518</td>\n",
       "      <td>0.167369</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.396678</td>\n",
       "      <td>0.162444</td>\n",
       "      <td>0.055740</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>0.422727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153682</td>\n",
       "      <td>0.617537</td>\n",
       "      <td>0.137308</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>0.519910</td>\n",
       "      <td>0.109158</td>\n",
       "      <td>0.089856</td>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.363493</td>\n",
       "      <td>0.173357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150930</td>\n",
       "      <td>0.174839</td>\n",
       "      <td>0.143459</td>\n",
       "      <td>0.071432</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>0.187811</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.064115</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109925</td>\n",
       "      <td>0.144723</td>\n",
       "      <td>0.096867</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.371987</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>0.392667</td>\n",
       "      <td>0.165027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090255</td>\n",
       "      <td>0.166723</td>\n",
       "      <td>0.103656</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.408053</td>\n",
       "      <td>0.410159</td>\n",
       "      <td>0.201640</td>\n",
       "      <td>0.142744</td>\n",
       "      <td>0.425253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064141</td>\n",
       "      <td>0.097281</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.024381</td>\n",
       "      <td>0.327082</td>\n",
       "      <td>0.209865</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.164467</td>\n",
       "      <td>0.135817</td>\n",
       "      <td>0.349993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220503</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>0.114104</td>\n",
       "      <td>0.555836</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.165651</td>\n",
       "      <td>0.173211</td>\n",
       "      <td>0.374242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.459488</td>\n",
       "      <td>0.174810</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.644720</td>\n",
       "      <td>0.231598</td>\n",
       "      <td>0.229473</td>\n",
       "      <td>0.418557</td>\n",
       "      <td>0.244628</td>\n",
       "      <td>0.235668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345923</td>\n",
       "      <td>0.240446</td>\n",
       "      <td>0.321401</td>\n",
       "      <td>0.207466</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.226263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>0.219284</td>\n",
       "      <td>0.122739</td>\n",
       "      <td>0.095754</td>\n",
       "      <td>0.022383</td>\n",
       "      <td>0.030879</td>\n",
       "      <td>0.114536</td>\n",
       "      <td>0.176030</td>\n",
       "      <td>0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331251</td>\n",
       "      <td>0.335137</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>0.193425</td>\n",
       "      <td>0.481809</td>\n",
       "      <td>0.288080</td>\n",
       "      <td>0.263824</td>\n",
       "      <td>0.321223</td>\n",
       "      <td>0.307576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324084</td>\n",
       "      <td>0.500533</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>0.168133</td>\n",
       "      <td>0.595192</td>\n",
       "      <td>0.319692</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.627835</td>\n",
       "      <td>0.318155</td>\n",
       "      <td>0.330972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.365573</td>\n",
       "      <td>0.231014</td>\n",
       "      <td>0.133701</td>\n",
       "      <td>0.248262</td>\n",
       "      <td>0.064413</td>\n",
       "      <td>0.055834</td>\n",
       "      <td>0.087972</td>\n",
       "      <td>0.342929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192458</td>\n",
       "      <td>0.554904</td>\n",
       "      <td>0.170178</td>\n",
       "      <td>0.089117</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.059503</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.255361</td>\n",
       "      <td>0.222551</td>\n",
       "      <td>0.090122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization",
   "id": "256912d21714e353"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:37:25.172864Z",
     "start_time": "2025-01-23T10:37:25.167807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def init(data, hidden_layer_nb=2, outputs_nb=2, weights_initializer='heUniform', hidden_nodes_nb=None):\n",
    "    X_train = data.iloc[:, 1:]\n",
    "    y_train = data.iloc[:, 0]\n",
    "    # One-hot encoding with 1 and 0\n",
    "    y_train = pd.get_dummies(y_train).values\n",
    "    \n",
    "    if hidden_nodes_nb is None:\n",
    "        hidden_nodes_nb = int(((X_train.shape[1] + outputs_nb) / 2))\n",
    "\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    for layer in range(hidden_layer_nb + 1):\n",
    "        # Input Layer to Hidden Layer\n",
    "        if layer == 0:\n",
    "            nodes_in = X_train.shape[1]\n",
    "            nodes_out = hidden_nodes_nb\n",
    "        # Hidden Layer to Hidden Layer\n",
    "        elif layer < hidden_layer_nb:\n",
    "            nodes_in = hidden_nodes_nb\n",
    "            nodes_out = hidden_nodes_nb\n",
    "        # Hidden Layer to Output Layer\n",
    "        else:\n",
    "            nodes_in = hidden_nodes_nb\n",
    "            nodes_out = outputs_nb\n",
    "            \n",
    "        if weights_initializer == 'xavier':\n",
    "            limit = np.sqrt(6 / (nodes_in + nodes_out))\n",
    "        else:\n",
    "            limit = np.sqrt(6 / nodes_in)\n",
    "        weights.append(np.random.uniform(-limit, limit, (nodes_out, nodes_in)))\n",
    "        biases.append(np.zeros(nodes_out))\n",
    "    \n",
    "    return hidden_nodes_nb, weights, biases, X_train, y_train\n",
    "    \n",
    "hidden_nodes_nb, weights, biases, X_train, y_train = init(train_data)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    print(f'weights[{i}]: {weights[i].shape}')\n",
    "    print(f'biases[{i}]: {biases[i].shape}\\n')\n"
   ],
   "id": "f5014a2046a7bf25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0]: (16, 30)\n",
      "biases[0]: (16,)\n",
      "\n",
      "weights[1]: (16, 16)\n",
      "biases[1]: (16,)\n",
      "\n",
      "weights[2]: (2, 16)\n",
      "biases[2]: (2,)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Activation function",
   "id": "6c68cf1c77a16878"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:53:27.924044Z",
     "start_time": "2025-01-23T11:53:27.914075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
   ],
   "id": "3ce0c1d5ade0ed30",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss function",
   "id": "3aff59d41c64a792"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:21:34.362213Z",
     "start_time": "2025-01-23T11:21:34.357516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(y_train, y_pred, loss='binary_cross_entropy'):\n",
    "    if loss == 'binary_cross_entropy':\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        # N = y_train.shape[0]\n",
    "        N = len(y_train)\n",
    "\n",
    "        loss = -(1/N) * np.sum(\n",
    "            y_train * np.log(y_pred) + \n",
    "            (1 - y_train) * np.log(1 - y_pred)\n",
    "        )\n",
    "    return loss"
   ],
   "id": "e216bdc13a8709f6",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Forwardpropagation",
   "id": "73cc82062c148765"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:43:03.548897Z",
     "start_time": "2025-01-23T11:43:03.543009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagation(X, weights, biases, activation='sigmoid', output_activation='softmax'):\n",
    "    layers = [X]  # List of layer activations\n",
    "    Z = []        # List of pre-activation values\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        z = np.dot(layers[i], weights[i].T) + biases[i]\n",
    "        Z.append(z)\n",
    "\n",
    "        # Compute activation\n",
    "        if i == len(weights) - 1:\n",
    "            if output_activation == 'softmax':\n",
    "                activation_output = softmax(z)\n",
    "            else:\n",
    "                activation_output = sigmoid(z)\n",
    "        else:\n",
    "            if activation == 'sigmoid':\n",
    "                activation_output = sigmoid(z)\n",
    "        \n",
    "        layers.append(activation_output)\n",
    "\n",
    "    return layers, Z"
   ],
   "id": "738dd7e41ba8098d",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backpropagation\n",
   "id": "95aad347318c1429"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:48:10.856369Z",
     "start_time": "2025-01-23T11:48:10.850042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward_propagation(y_true, activations, Z, weights):\n",
    "    gradients = {\"dW\": [], \"db\": []}\n",
    "    num_layers = len(weights)\n",
    "    m = y_true.shape[0]  # Number of samples\n",
    "\n",
    "    delta = (activations[-1] - y_true) / m\n",
    "\n",
    "    for i in reversed(range(num_layers)):\n",
    "        dW = np.dot(delta.T, activations[i])\n",
    "        db = np.sum(delta, axis=0)\n",
    "        \n",
    "        gradients[\"dW\"].insert(0, dW)\n",
    "        gradients[\"db\"].insert(0, db)\n",
    "\n",
    "        if i > 0:\n",
    "            delta = np.dot(delta, weights[i]) * sigmoid_derivative(Z[i-1])  # Apply to Z instead of A\n",
    "\n",
    "    return gradients\n"
   ],
   "id": "a8c9e07093a70cc",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:15:00.612514Z",
     "start_time": "2025-01-23T10:15:00.608487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_parameters(weights, biases, gradients, learning_rate):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= learning_rate * gradients[\"dW\"][i]\n",
    "        biases[i] -= learning_rate * gradients[\"db\"][i]\n",
    "    return weights, biases"
   ],
   "id": "5d6c77546b4a5f3c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the model",
   "id": "f63321d7aba2ac3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:14:04.968526Z",
     "start_time": "2025-01-23T12:14:04.860619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_data, hidden_layer_nb=2, output_nb = 2,  epochs=1000, learning_rate=0.005, batch_size=8, patience_early_stop=5):\n",
    "    \n",
    "    # Initialize weights/biases for variable hidden layers + output\n",
    "    hidden_nodes_nb, weights, biases, X_train, y_train = init(train_data, hidden_layer_nb, output_nb, 'xavier')\n",
    "\n",
    "    n_samples = X_train.shape[0]\n",
    "    wait = 0\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data\n",
    "        # permutation = np.random.permutation(n_samples)\n",
    "        # X_shuffled = X_train.iloc[permutation]\n",
    "        # print(y_train.shape)\n",
    "        # y_shuffled = y_train[permutation]\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # for i in range(0, n_samples, batch_size):\n",
    "        # X_batch = X_shuffled[i:i+batch_size]\n",
    "        # y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        activations, Z = forward_propagation(X_train, weights, biases)\n",
    "            # activations = forward_propagation(X_shuffled, weights, biases)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = round(evaluate(y_train, activations[-1]), 4)\n",
    "        if (loss < best_val_loss):\n",
    "            best_val_loss = loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience_early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        epoch_loss += loss\n",
    "\n",
    "        # Backward pass\n",
    "        # print(\"y_true shape:\", y_train.shape)\n",
    "        # print(\"activations shapes:\", [a.shape for a in activations])\n",
    "        # print(\"Z shapes:\", [z.shape for z in Z])\n",
    "        # print(\"weights shapes:\", [w.shape for w in weights])\n",
    "        gradients = backward_propagation(y_train, activations, Z, weights)\n",
    "\n",
    "        # Update parameters\n",
    "        weights, biases = update_parameters(weights, biases, gradients, learning_rate)\n",
    "\n",
    "        # Print loss every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            avg_loss = epoch_loss / (n_samples // batch_size)\n",
    "            print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return weights, biases\n",
    "train(train_data)"
   ],
   "id": "1fae49cb1ea139d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0255\n",
      "Epoch 100, Loss: 0.0239\n",
      "Epoch 200, Loss: 0.0237\n",
      "Early stopping at epoch 276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([[-0.12931271, -0.13416215, -0.34102212,  0.09813615, -0.30318397,\n",
       "           0.26084201, -0.13023243, -0.2759634 ,  0.25681964, -0.10143031,\n",
       "           0.16060525, -0.09023694,  0.33549415,  0.20796075, -0.27691532,\n",
       "           0.28632397, -0.30621635,  0.30353241, -0.31997522, -0.10480585,\n",
       "          -0.33956804, -0.05538815, -0.284549  ,  0.31504915, -0.20204106,\n",
       "          -0.36798903, -0.05746599, -0.26846666, -0.15874352, -0.34895314],\n",
       "         [ 0.22796025,  0.17798473, -0.00896696,  0.14545657,  0.02856799,\n",
       "          -0.24398776,  0.01845693,  0.12506887,  0.23474707,  0.31669363,\n",
       "           0.06882764, -0.25307165,  0.30466431, -0.12952947,  0.15113327,\n",
       "           0.26012253, -0.20109429,  0.22460674,  0.30567685,  0.02960997,\n",
       "          -0.06058354, -0.14194259,  0.34031694, -0.2909892 ,  0.20785367,\n",
       "          -0.29509878, -0.29737292,  0.30130437,  0.31863856,  0.2154544 ],\n",
       "         [ 0.20494989, -0.36211471,  0.15164748, -0.06512551,  0.07751313,\n",
       "          -0.31254863,  0.18807595, -0.30941673,  0.060493  ,  0.20185969,\n",
       "           0.19540963, -0.11291405, -0.31852365,  0.26293453,  0.3368148 ,\n",
       "           0.26723472, -0.25052879, -0.07460557, -0.17567608,  0.35084332,\n",
       "           0.05584828,  0.23227058,  0.09559186, -0.02042031,  0.2679861 ,\n",
       "          -0.26188975,  0.29625857,  0.05548254, -0.25339751, -0.09291232],\n",
       "         [ 0.01646377, -0.01938363,  0.13435831, -0.32802261, -0.09403815,\n",
       "          -0.06585435, -0.08131379,  0.14588253, -0.12153703, -0.21635143,\n",
       "           0.10467912, -0.35296284,  0.24134493, -0.23552107,  0.10110833,\n",
       "          -0.01095083, -0.01488418,  0.23917676,  0.16540522,  0.07931393,\n",
       "           0.04787817, -0.10204122,  0.09684381, -0.06521831,  0.34140379,\n",
       "          -0.32374266,  0.03346257, -0.00673655, -0.10850604, -0.29119812],\n",
       "         [ 0.05263782,  0.20188141, -0.23799294,  0.1873505 , -0.30782328,\n",
       "          -0.12188722,  0.0330034 ,  0.35739101, -0.15853888, -0.1119978 ,\n",
       "          -0.22777118,  0.21282597, -0.01443098, -0.03136728,  0.37145038,\n",
       "           0.20729832, -0.22213759, -0.31069473, -0.23552191,  0.37138275,\n",
       "          -0.23276089,  0.31684364, -0.12036102, -0.22501165, -0.05369185,\n",
       "           0.01161673, -0.09975195, -0.26672316,  0.11057583,  0.03892428],\n",
       "         [ 0.24997276,  0.03355132,  0.01189622,  0.26851935,  0.17613633,\n",
       "           0.09697944,  0.08708808, -0.11338682,  0.22259618, -0.1251871 ,\n",
       "           0.22836932, -0.3018845 ,  0.2488021 ,  0.00626575, -0.1102891 ,\n",
       "          -0.02286714, -0.15698465,  0.19967465, -0.28500614,  0.31111878,\n",
       "           0.12551391, -0.23593616,  0.0899645 ,  0.20464148, -0.08497891,\n",
       "           0.23007246,  0.16627667,  0.1003094 , -0.15313973, -0.0336863 ],\n",
       "         [-0.29277565,  0.3394111 ,  0.12425952, -0.10336709, -0.02677257,\n",
       "           0.2176618 ,  0.02257489, -0.12503904,  0.17017625, -0.10241643,\n",
       "          -0.30061299, -0.18217651,  0.32915246, -0.0142102 , -0.28945788,\n",
       "          -0.33660268,  0.06706192,  0.17351501,  0.13018977,  0.12349253,\n",
       "           0.1359334 , -0.30902475,  0.15702142, -0.12087351, -0.32503096,\n",
       "          -0.17799983, -0.12435829, -0.03393062,  0.17906654,  0.06558167],\n",
       "         [ 0.35741558,  0.09744751, -0.21407691,  0.14532722,  0.05788237,\n",
       "           0.0190607 , -0.0495123 , -0.1700935 , -0.19366041,  0.06821209,\n",
       "          -0.05751207,  0.15137801,  0.26192446,  0.13023763,  0.07912579,\n",
       "          -0.11758086,  0.31446977,  0.20687528,  0.01115774, -0.02324267,\n",
       "           0.19645024, -0.20868339, -0.0947884 , -0.2647583 ,  0.20658049,\n",
       "           0.34240405,  0.22369645,  0.32521697,  0.03845229,  0.12812507],\n",
       "         [ 0.25647718, -0.07662185, -0.01049736,  0.00613555,  0.2695106 ,\n",
       "           0.01699303, -0.24025647,  0.04349986, -0.15552391,  0.13127663,\n",
       "           0.06830362, -0.10742966,  0.24505763, -0.25921832, -0.12921421,\n",
       "           0.17771062,  0.23625619, -0.03404443, -0.16858117,  0.05749388,\n",
       "           0.14712547,  0.03173895, -0.15339588, -0.33328647,  0.15561149,\n",
       "          -0.01910502,  0.31572481, -0.21783455,  0.00496496, -0.15188232],\n",
       "         [-0.33056313, -0.2549417 , -0.06275553, -0.13973433, -0.05004525,\n",
       "          -0.12709469, -0.26251421, -0.25509363,  0.25044419,  0.0936719 ,\n",
       "           0.29279296, -0.0036057 ,  0.13380042,  0.05199527,  0.28274987,\n",
       "           0.35661575,  0.21985827,  0.0697395 ,  0.32814433, -0.21078339,\n",
       "           0.15592846, -0.04719081,  0.33326979,  0.17836659,  0.24149737,\n",
       "          -0.2060021 ,  0.08993524, -0.23401071,  0.15633413, -0.03475632],\n",
       "         [ 0.30329033, -0.2917539 ,  0.21513807,  0.17282103, -0.23638721,\n",
       "           0.0167714 , -0.31671241,  0.08939391, -0.08321982,  0.1733391 ,\n",
       "          -0.16414774,  0.30407598,  0.33894014, -0.01654371, -0.3572126 ,\n",
       "          -0.25729085,  0.1063481 ,  0.23560171,  0.26423204, -0.22274654,\n",
       "          -0.35324638, -0.05180087,  0.10778377, -0.35192312,  0.09489887,\n",
       "          -0.12183958, -0.00859164, -0.26292265, -0.21089783,  0.0524697 ],\n",
       "         [-0.05455085, -0.04909971, -0.16511962,  0.08724487, -0.24947407,\n",
       "           0.06113536, -0.08185709, -0.03960239, -0.19949589, -0.22065966,\n",
       "          -0.16942872, -0.26111542, -0.05312389, -0.1094849 ,  0.31935716,\n",
       "           0.19812191, -0.28342363,  0.10362653,  0.07567011,  0.24305624,\n",
       "          -0.28754783, -0.12017763, -0.07059058,  0.32004088,  0.12907657,\n",
       "           0.15722668,  0.27706385,  0.18057098,  0.04491197,  0.057564  ],\n",
       "         [ 0.23834233, -0.17996927,  0.20613815, -0.0374086 ,  0.31956544,\n",
       "          -0.08159144, -0.28563671,  0.06715458, -0.28625174,  0.28223875,\n",
       "           0.20843766,  0.22357491,  0.25060389, -0.1841459 , -0.28271095,\n",
       "          -0.00070873,  0.09168042, -0.04841503, -0.28070606, -0.21683126,\n",
       "           0.20905486,  0.06904358,  0.11944694,  0.19657194,  0.23445528,\n",
       "           0.0952753 ,  0.12532284, -0.02431966,  0.05621948,  0.13920068],\n",
       "         [ 0.23369373, -0.06762657, -0.1537044 ,  0.33852041, -0.11274904,\n",
       "          -0.167674  ,  0.08310582,  0.03448208, -0.05918722,  0.08238333,\n",
       "          -0.21024436,  0.22784344, -0.00297439,  0.00310092,  0.11246676,\n",
       "           0.22960457,  0.24016284, -0.30359885,  0.15854061, -0.279475  ,\n",
       "           0.3386617 ,  0.1371784 , -0.33948265, -0.25770114,  0.03174752,\n",
       "           0.12412814,  0.00438091,  0.06262447, -0.22710939,  0.06711301],\n",
       "         [ 0.23868341,  0.12763051,  0.0202036 , -0.30862548,  0.14433594,\n",
       "           0.20999832,  0.19984648,  0.24786528,  0.24168369,  0.28073822,\n",
       "          -0.18562209,  0.17968869,  0.19430798,  0.05915406,  0.35362983,\n",
       "          -0.3579507 ,  0.27895448, -0.05074733,  0.34939931, -0.07038837,\n",
       "          -0.08613162, -0.1196704 , -0.35748205,  0.06989   ,  0.30949403,\n",
       "          -0.00220283,  0.08069143,  0.31764672, -0.07612333, -0.34484934],\n",
       "         [-0.07251459, -0.08683025, -0.02426928,  0.02406884,  0.20601921,\n",
       "           0.22627221,  0.01278832,  0.23562953,  0.18007166, -0.18884462,\n",
       "          -0.25862442,  0.31080796, -0.14880052, -0.15907529, -0.06708708,\n",
       "          -0.34710886, -0.05039525, -0.13252519,  0.35709707,  0.30400089,\n",
       "          -0.16888203,  0.04115762, -0.13524546, -0.31294176,  0.34829654,\n",
       "           0.08490653,  0.20140848, -0.18511954, -0.31076944,  0.30696873]]),\n",
       "  array([[-0.40282169,  0.02716138,  0.10511012, -0.23132473,  0.29321191,\n",
       "          -0.25877376, -0.26151233, -0.16478769,  0.0123512 , -0.16143747,\n",
       "           0.35106144,  0.3922656 ,  0.3380778 , -0.16412718, -0.36323411,\n",
       "           0.32336303],\n",
       "         [-0.39646776, -0.04771115, -0.30990419,  0.01471838, -0.37770032,\n",
       "           0.38679869,  0.34842672, -0.30974442,  0.11474404,  0.35956144,\n",
       "           0.14731965,  0.19555022,  0.22321658,  0.10496202,  0.15582164,\n",
       "          -0.03860964],\n",
       "         [-0.32807233, -0.03515215,  0.21552866,  0.33326829,  0.44148157,\n",
       "          -0.26330464, -0.37430152, -0.30082312, -0.08870062,  0.04372736,\n",
       "           0.11061639,  0.13144424, -0.14744844, -0.25281663, -0.41359423,\n",
       "          -0.39865938],\n",
       "         [-0.14352349,  0.00432979,  0.21743348, -0.37447752,  0.12469592,\n",
       "           0.39752687,  0.34505739,  0.20132378,  0.40816299, -0.35180294,\n",
       "          -0.15688639,  0.3220385 , -0.32792639, -0.36503992,  0.41738217,\n",
       "          -0.1695668 ],\n",
       "         [ 0.20258766,  0.33787224, -0.32431476, -0.12226249, -0.35891519,\n",
       "          -0.34701825,  0.41033506,  0.26694131, -0.00844876, -0.32077894,\n",
       "           0.25200993, -0.15945984,  0.21490493,  0.24525675,  0.09844289,\n",
       "          -0.33944705],\n",
       "         [-0.08228689, -0.25326801, -0.11053826, -0.31655895, -0.0903998 ,\n",
       "          -0.1333536 , -0.45119782,  0.04968451, -0.15457387,  0.10173735,\n",
       "           0.3281683 ,  0.38835727,  0.25674727, -0.41081651, -0.42677945,\n",
       "           0.14227907],\n",
       "         [ 0.37657027,  0.19851306, -0.00137165,  0.29188155, -0.29612577,\n",
       "           0.40317572,  0.21172078, -0.01846505,  0.29401777,  0.2247993 ,\n",
       "          -0.15163099,  0.15725576, -0.32922833, -0.13377232, -0.25728069,\n",
       "          -0.07596618],\n",
       "         [ 0.33269209, -0.12904161,  0.33803005,  0.04672008,  0.03639391,\n",
       "           0.09133684,  0.18448206,  0.27628873,  0.43046081,  0.1121179 ,\n",
       "           0.19210326, -0.19819589,  0.34229514, -0.04263078, -0.14296636,\n",
       "           0.20642495],\n",
       "         [ 0.23256586,  0.14798338, -0.1513892 , -0.10708506, -0.08114125,\n",
       "          -0.07284942,  0.3590893 ,  0.14430762,  0.39585812, -0.04191762,\n",
       "          -0.37350708,  0.02135773, -0.3482695 ,  0.15236004, -0.17054367,\n",
       "           0.24001341],\n",
       "         [-0.29680881,  0.0153167 ,  0.26563762, -0.02468021,  0.10622357,\n",
       "          -0.07736795, -0.14047354,  0.18648809, -0.02324089, -0.03189603,\n",
       "          -0.12008866,  0.20301406,  0.32027426, -0.00061519, -0.41682367,\n",
       "          -0.26160375],\n",
       "         [-0.2822468 , -0.36930512, -0.33662233,  0.12658821, -0.0336117 ,\n",
       "          -0.23406052,  0.2982892 , -0.19833598, -0.01476122, -0.41240381,\n",
       "           0.18634153, -0.09465829, -0.2545871 ,  0.40177061, -0.2395781 ,\n",
       "          -0.1959464 ],\n",
       "         [-0.12042367,  0.27540399, -0.39212012, -0.13282538, -0.19781612,\n",
       "           0.37581246, -0.44804419, -0.1114582 , -0.04465719, -0.47875064,\n",
       "           0.08007386, -0.29762586, -0.46378605, -0.18806695, -0.32894401,\n",
       "          -0.39404484],\n",
       "         [-0.11063397, -0.37677776, -0.30799336, -0.11922434, -0.14855463,\n",
       "          -0.30574152, -0.24642948,  0.18210422,  0.10096966, -0.04783696,\n",
       "           0.10598201, -0.13335019,  0.32240754, -0.20962994,  0.26860356,\n",
       "           0.28683329],\n",
       "         [-0.03965264,  0.29415095,  0.42039269, -0.31678702,  0.20967141,\n",
       "          -0.16761365,  0.35096701,  0.06558261, -0.01368501,  0.27874587,\n",
       "          -0.19469765, -0.34419929, -0.14767232,  0.2638289 ,  0.38902082,\n",
       "           0.36830485],\n",
       "         [ 0.00498211,  0.35389031, -0.00759057,  0.41191102,  0.1909343 ,\n",
       "           0.07247611,  0.09392117, -0.1273071 , -0.37926827, -0.28822785,\n",
       "           0.21604523, -0.19460392,  0.0016902 ,  0.07848877,  0.38282404,\n",
       "           0.30724381],\n",
       "         [-0.36987458,  0.34240416,  0.1809663 , -0.24930353, -0.4080102 ,\n",
       "           0.3138985 , -0.35875822,  0.28000942,  0.37498858, -0.35633728,\n",
       "           0.32490912,  0.11092042,  0.29657854, -0.06814354, -0.43106069,\n",
       "           0.08041629]]),\n",
       "  array([[-0.39649425, -0.40740031,  0.09164437, -0.17705873, -0.37493671,\n",
       "           0.54299228, -0.37279353, -0.32258853,  0.35507386,  0.09269691,\n",
       "           0.28585431,  0.24850214,  0.59285994,  0.3354489 ,  0.54735203,\n",
       "           0.06101757],\n",
       "         [ 0.35429075, -0.07574901,  0.46833305,  0.23309032, -0.54748835,\n",
       "          -0.08713101,  0.30125193, -0.34831391, -0.05501139,  0.1754667 ,\n",
       "           0.4797878 , -0.2859125 , -0.14942417,  0.27686337, -0.33054204,\n",
       "          -0.33569291]])],\n",
       " [array([-0.04521888, -0.0140266 , -0.0006742 ,  0.01606466,  0.09212168,\n",
       "          0.01308727,  0.04322582, -0.00012746, -0.00104231,  0.01699755,\n",
       "         -0.01245581, -0.00243941,  0.00416596, -0.00460074,  0.01563812,\n",
       "          0.00901324]),\n",
       "  array([-5.83574234e-04, -4.23617207e-03,  1.75560659e-02, -4.36057724e-03,\n",
       "         -4.41795642e-04, -2.93146756e-02, -1.24428038e-02,  6.81137446e-05,\n",
       "          6.05068552e-03,  2.63750181e-03,  1.68560571e-02, -1.18921578e-01,\n",
       "         -2.12347348e-02,  1.25546744e-04,  1.42818244e-02, -3.53353532e-03]),\n",
       "  array([ 0.06758843, -0.06758843])])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 235
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
